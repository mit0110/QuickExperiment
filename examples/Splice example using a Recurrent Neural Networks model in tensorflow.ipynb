{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Network model for regression in sequences\n",
    "====\n",
    "\n",
    "In this example we will use the RNNModel to set up an experiment over one of the Spice (http://spice.lif.univ-mrs.fr/index.php) competence for sequence prediction, held in 2016. We will start by downloading and preprocessing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ORIGIN_URL = 'http://spice.lif.univ-mrs.fr/data/1.spice.train'\n",
    "DATASET_DIR = 'downloads'\n",
    "DATASET_FILENAME = 'spice_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add parent directory to python path\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import urllib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "utils.safe_mkdir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maybe_download():\n",
    "    \"\"\"Downloads dataset if it doesn't exists\"\"\"\n",
    "    filename = os.path.join(DATASET_DIR, DATASET_FILENAME)\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    urllib.urlretrieve(ORIGIN_URL, filename)\n",
    "\n",
    "maybe_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset file consists on a series of numerical sequences, one per line, including a header line that we will ignore. We will try to predict the last element of each sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    \"\"\"Reads the dataset. Returns a list with sequences and a list of labels\"\"\"\n",
    "    with open(os.path.join(DATASET_DIR, DATASET_FILENAME), 'r') as input_file:\n",
    "        lines = input_file.readlines()[1:]  # Ignore the header\n",
    "    # Split lines and convert numbers to int.\n",
    "    sequences = [[numpy.array([int(value)], dtype=numpy.int16) for value in line.split()] for line in lines]\n",
    "    instances = [sequence[:-1] for sequence in sequences]\n",
    "    labels = [sequence[-1] for sequence in sequences]\n",
    "    return numpy.array(instances), numpy.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instances, labels = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the dataset using the extracted instances and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dataset\n",
    "dataset = reload(dataset)\n",
    "\n",
    "samples = 1\n",
    "partition_sizes = {'train': 0.7, 'test': 0.2, 'validation': 0.1}\n",
    "\n",
    "splice_dataset = dataset.SequenceDataset()\n",
    "splice_dataset.create_samples(instances, labels, samples, partition_sizes, use_numeric_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import experiment\n",
    "experiment = reload(experiment)\n",
    "from models import lstm, mlp\n",
    "mlp = reload(mlp)\n",
    "lstm = reload(lstm)\n",
    "\n",
    "config = {\n",
    "    'model': lstm.LSTMModel,\n",
    "    'model_arguments': {'hidden_layer_size': 50, 'batch_size': 100,\n",
    "                        'logs_dirname': '../../results/examples/splice/',\n",
    "                        'log_values': True, 'training_epochs': 1000}\n",
    "}\n",
    "splice_experiment = experiment.SampledExperiment(splice_dataset, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Classifier loss at step 0: 2.99467945099\n",
      "INFO:root:Validation accuracy 0.32316158079\n",
      "INFO:root:Classifier loss at step 100: 2.8269238472\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 200: 2.86058950424\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 300: 2.81255316734\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 400: 2.81250476837\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 500: 2.84739565849\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 600: 2.83434700966\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 700: 2.89007878304\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 800: 2.83562874794\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:Classifier loss at step 900: 2.86018514633\n",
      "INFO:root:Validation accuracy 0.150575287644\n",
      "INFO:root:\n",
      "\tPrecision\tRecall\tF1 Score\n",
      "mean\t0.15175\t0.15175\t0.15175\n",
      "std\t0.0\t0.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "splice_experiment.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
