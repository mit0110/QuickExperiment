{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Network model for regression in sequences\n",
    "====\n",
    "\n",
    "In this example we will use the RNNModel to set up an experiment over one of the Spice (http://spice.lif.univ-mrs.fr/index.php) competence for sequence prediction, held in 2016. We will start by downloading and preprocessing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ORIGIN_URL = 'http://spice.lif.univ-mrs.fr/data/2.spice.train'\n",
    "DATASET_DIR = 'downloads'\n",
    "DATASET_FILENAME = 'spice_dataset2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add parent directory to python path\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import urllib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from quick_experiment import utils\n",
    "utils.safe_mkdir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maybe_download():\n",
    "    \"\"\"Downloads dataset if it doesn't exists\"\"\"\n",
    "    filename = os.path.join(DATASET_DIR, DATASET_FILENAME)\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "    urllib.urlretrieve(ORIGIN_URL, filename)\n",
    "\n",
    "maybe_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset file consists on a series of numerical sequences, one per line, including a header line that we will ignore. We will try to predict the last element of each sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def get_instances(elements, sequences):\n",
    "    \"\"\"Converts the elements to one hot encodings and divides them according to sequences.\"\"\"\n",
    "    encoder = OneHotEncoder()\n",
    "    elements = encoder.fit_transform(elements)\n",
    "    instances = []\n",
    "    for start, end in sequences:\n",
    "        instances.append(elements[start:end])\n",
    "    return instances\n",
    "\n",
    "\n",
    "def read_dataset():\n",
    "    \"\"\"Reads the dataset. Returns a list with sequences and a list of labels\"\"\"\n",
    "    with open(os.path.join(DATASET_DIR, DATASET_FILENAME), 'r') as input_file:\n",
    "        lines = input_file.readlines()[1:]  # Ignore the header\n",
    "    # Split lines and convert numbers to one hot encodings.\n",
    "    sequences = []  # A list with start, end of each sequence.\n",
    "    elements = []\n",
    "    labels = []\n",
    "    current_start = 0\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        # We discard the first element (sequence lenght) and the last one (sequence label)\n",
    "        sequences.append((current_start, current_start + len(values) - 2))\n",
    "        current_start += len(values) - 2\n",
    "        for value in values[1:-1]:\n",
    "            elements.append([int(value)])\n",
    "        labels.append(values[-1])\n",
    "    instances = get_instances(elements, sequences)\n",
    "    return numpy.array(instances), numpy.array(labels)\n",
    "\n",
    "instances, labels = read_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the dataset using the extracted instances and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from quick_experiment import dataset\n",
    "dataset = reload(dataset)\n",
    "\n",
    "samples = 1\n",
    "partition_sizes = {'train': 0.7, 'test': 0.2, 'validation': 0.1}\n",
    "\n",
    "splice_dataset = dataset.SequenceDataset()\n",
    "splice_dataset.create_samples(instances, labels, samples, partition_sizes, use_numeric_labels=True)\n",
    "logs_dirname = '../../results/examples/splice/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove previous directory\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(logs_dirname)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from quick_experiment import experiment\n",
    "experiment = reload(experiment)\n",
    "from quick_experiment.models import lstm, mlp\n",
    "mlp = reload(mlp)\n",
    "lstm = reload(lstm)\n",
    "\n",
    "utils.safe_mkdir(logs_dirname)\n",
    "\n",
    "config = {\n",
    "    'model': lstm.LSTMModel,\n",
    "    'model_arguments': {'hidden_layer_size': 20, 'batch_size': 5,\n",
    "                        'logs_dirname': logs_dirname,\n",
    "                        'log_values': 100, 'training_epochs': 1000, 'max_num_steps': 10}\n",
    "}\n",
    "splice_experiment = experiment.SampledExperiment(splice_dataset, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating model for sample 0\n",
      "INFO:root:Training model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model trained\n",
      "INFO:root:\n",
      "\tPrecision\tRecall\tF1 Score\n",
      "mean\t0.2215\t0.2215\t0.2215\n",
      "std\t0.0\t0.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "splice_experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are obtaining a very low accuracy, let's see what's going on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions, true = splice_experiment.model.predict('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2215"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=true, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([370, 336, 235, 438, 415, 415, 836, 221, 499, 235]))\n",
      "[6 4 6 ..., 6 6 6] (array([3, 4, 5, 6]), array([   1,   79,    6, 3914]))\n"
     ]
    }
   ],
   "source": [
    "print numpy.unique(true, return_counts=True)\n",
    "print predictions, numpy.unique(predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see too much difference between the validation and test accuracy, and the labels predicted are \"evenly\" distributed. This tell us that the problem is the network does not have enough information to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Seq2Seq prediction\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome the problem above, we are going to train now a model that predicts the next element on the sequence. We need to re-process the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def get_instances(elements, sequences):\n",
    "    \"\"\"Converts the elements to one hot encodings and divides them according to sequences.\"\"\"\n",
    "    encoder = OneHotEncoder()\n",
    "    elements = encoder.fit_transform(elements)\n",
    "    instances = []\n",
    "    for start, end in sequences:\n",
    "        instances.append(elements[start:end])\n",
    "    return instances\n",
    "\n",
    "\n",
    "def read_dataset():\n",
    "    \"\"\"Reads the dataset. Returns a list with sequences and a list of labels\"\"\"\n",
    "    with open(os.path.join(DATASET_DIR, DATASET_FILENAME), 'r') as input_file:\n",
    "        lines = input_file.readlines()[1:]  # Ignore the header\n",
    "    # Split lines and convert numbers to one hot encodings.\n",
    "    sequences = []  # A list with start, end of each sequence.\n",
    "    elements = []\n",
    "    labels = []\n",
    "    current_start = 0\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        # We discard the first element (sequence lenght)\n",
    "        sequences.append((current_start, current_start + len(values) - 1))\n",
    "        current_start += len(values) - 1\n",
    "        for value in values[1:]:\n",
    "            elements.append([int(value)])\n",
    "    instances = get_instances(elements, sequences)\n",
    "    return numpy.array(instances)\n",
    "\n",
    "instances = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from quick_experiment import dataset\n",
    "dataset = reload(dataset)\n",
    "\n",
    "samples = 1\n",
    "partition_sizes = {'train': 0.7, 'test': 0.2, 'validation': 0.1}\n",
    "\n",
    "unlabeled_splice_dataset = dataset.UnlabeledSequenceDataset()\n",
    "unlabeled_splice_dataset.create_samples(instances, None, samples, partition_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from quick_experiment import experiment\n",
    "experiment = reload(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_dirname = '../../results/examples/splice/sequence'\n",
    "\n",
    "# Remove previous directory\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(logs_dirname)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "utils.safe_mkdir(logs_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import logging\n",
    "\n",
    "class SequenceExperiment(experiment.SampledExperiment):\n",
    "\n",
    "    def _get_metrics(self, predictions):\n",
    "        \"\"\"Logs the values of the metric for the given predictions.\n",
    "        \n",
    "        Args:\n",
    "            predictions: 2-uple. Both elements are arrays of shape [batch_size, sequence_lengths].\n",
    "        \"\"\"\n",
    "        metric_values = []\n",
    "        for true, prediction in predictions:\n",
    "            metric_values.append(metrics.precision_recall_fscore_support(\n",
    "                numpy.concatenate(true), numpy.concatenate(prediction), average='micro'\n",
    "            )[:-1])\n",
    "        metric_values = numpy.array(metric_values)\n",
    "        report = ('\\n\\tPrecision\\tRecall\\tF1 Score\\n' + 'mean\\t' +\n",
    "            '\\t'.join([str(x) for x in metric_values.mean(axis=0)]) +\n",
    "            '\\nstd\\t' + '\\t'.join([str(x) for x in metric_values.std(axis=0)])\n",
    "        )\n",
    "        logging.info(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from quick_experiment.models import seq_lstm\n",
    "config = {\n",
    "    'model': seq_lstm.SeqLSTMModel,\n",
    "    'model_arguments': {'hidden_layer_size': 20, 'batch_size': 25,\n",
    "                        'logs_dirname': logs_dirname, 'learning_rate': 0.01,\n",
    "                        'log_values': 100, 'training_epochs': 1000, 'max_num_steps': 20}\n",
    "}\n",
    "sequence_splice_experiment = SequenceExperiment(unlabeled_splice_dataset, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating model for sample 0\n",
      "INFO:root:Training model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Classifier loss at step 100 (0.06s): 2.32234048843\n",
      "Validation performance 0.201591193676\n",
      "Classifier loss at step 200 (0.09s): 2.29971575737\n",
      "Validation performance 0.206646263599\n",
      "Classifier loss at step 300 (0.09s): 2.17955088615\n",
      "Validation performance 0.18696449697\n",
      "Classifier loss at step 400 (0.09s): 2.16690039635\n",
      "Validation performance 0.182362303138\n",
      "Classifier loss at step 500 (0.09s): 2.16062998772\n",
      "Validation performance 0.180122405291\n",
      "Classifier loss at step 600 (0.09s): 2.15684652328\n",
      "Validation performance 0.177772343159\n",
      "Classifier loss at step 700 (0.09s): 2.15424728394\n",
      "Validation performance 0.176242351532\n",
      "Classifier loss at step 800 (0.09s): 2.15257668495\n",
      "Validation performance 0.175250917673\n",
      "Classifier loss at step 900 (0.09s): 2.1512966156\n",
      "Validation performance 0.174859240651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model trained\n",
      "INFO:root:\n",
      "\tPrecision\tRecall\tF1 Score\n",
      "mean\t0.179975294349\t0.179975294349\t0.179975294349\n",
      "std\t0.0\t0.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sequence_splice_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions, true = sequence_splice_experiment.model.predict('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([  0.,   7.,   3.,   8.,   5.,   8.,   8.,   7.,   8.,   2.,   8.,\n",
       "         5.,   5.,   7.,   4.,   0.,   6.,   8.,   8.,   1.,   5.,   1.,\n",
       "         0.,   6.,   0.,   2.,   8.,   8.,   6.,   5.,   1.,   1.,   6.,\n",
       "        10.]),\n",
       "       array([  6.,   3.,   1.,   4.,   6.,   0.,   5.,   6.,   4.,   8.,   5.,\n",
       "         9.,   6.,   4.,   6.,   5.,   3.,   0.,   5.,   0.,   6.,   6.,\n",
       "         4.,   6.,   3.,   2.,   6.,   6.,   2.,   3.,   5.,   6.,   5.,\n",
       "         0.,   4.,   3.,   6.,   4.,   9.,   9.,   4.,   2.,   4.,   3.,\n",
       "         0.,   6.,   4.,   8.,   8.,   1.,   4.,   8.,   3.,   8.,   6.,\n",
       "         4.,  10.]),\n",
       "       array([  1.,   2.,   6.,   2.,   3.,   0.,   6.,   4.,   8.,   0.,   6.,\n",
       "         4.,   6.,   5.,   3.,   6.,   3.,   3.,   3.,   0.,   7.,   4.,\n",
       "         5.,   8.,   4.,   6.,   6.,   3.,   1.,   0.,   4.,   2.,   1.,\n",
       "         5.,   7.,   9.,   1.,   5.,   4.,   6.,   9.,   8.,   3.,   6.,\n",
       "        10.]),\n",
       "       array([  8.,   8.,   4.,   0.,   1.,   5.,   6.,   4.,   7.,   1.,   5.,\n",
       "         6.,   6.,   3.,   6.,   3.,   7.,   0.,   0.,   6.,   4.,   4.,\n",
       "         6.,   9.,   5.,   6.,   7.,   3.,   1.,   5.,  10.]),\n",
       "       array([  6.,   6.,   2.,   9.,   9.,   5.,   4.,   1.,   5.,   6.,   2.,\n",
       "         6.,   3.,   9.,   4.,   4.,   0.,   1.,   1.,   4.,   7.,   8.,\n",
       "         3.,  10.]),\n",
       "       array([  2.,   2.,   4.,   9.,   9.,   0.,   2.,   6.,   1.,   9.,   8.,\n",
       "         8.,  10.]),\n",
       "       array([  8.,   0.,   6.,   5.,   0.,   9.,   8.,   2.,   2.,   8.,   9.,\n",
       "         4.,   8.,   4.,   3.,   0.,   8.,   2.,   3.,   8.,   3.,   0.,\n",
       "         2.,   3.,   5.,   6.,   4.,   8.,   3.,   8.,   6.,   5.,   3.,\n",
       "         6.,   3.,   1.,   4.,   0.,   2.,   4.,   7.,   6.,   9.,   3.,\n",
       "         0.,   6.,   8.,   5.,   3.,   6.,   6.,   3.,   9.,  10.]),\n",
       "       array([  2.,   5.,   1.,   0.,   4.,   5.,   8.,   8.,   1.,   5.,   0.,\n",
       "         8.,  10.]),\n",
       "       array([  4.,   5.,   7.,   3.,   6.,   7.,   8.,   8.,   0.,   0.,   6.,\n",
       "         5.,   0.,   6.,   5.,   8.,   5.,  10.]),\n",
       "       array([  7.,   3.,   5.,   6.,   0.,   5.,   5.,   2.,   0.,   0.,   8.,\n",
       "         8.,   6.,   6.,   8.,   2.,   5.,   6.,   4.,   9.,   5.,   6.,\n",
       "         6.,   6.,   0.,   0.,   6.,   2.,   5.,   8.,   1.,   4.,   6.,\n",
       "         5.,   1.,   0.,   1.,   4.,   5.,   1.,   5.,   4.,   5.,   6.,\n",
       "         5.,   4.,   4.,   8.,   9.,   4.,   3.,   7.,   8.,   3.,   6.,\n",
       "         7.,   8.,   8.,   3.,   9.,   6.,   5.,   1.,   0.,   6.,   1.,\n",
       "         3.,   3.,   6.,   2.,   1.,   5.,   8.,   4.,   1.,   8.,   3.,\n",
       "         0.,   1.,   1.,   1.,   6.,   9.,   4.,   5.,   8.,   4.,   2.,\n",
       "         0.,   3.,   5.,   8.,   6.,   7.,   6.,   9.,   2.,   0.,   3.,\n",
       "         5.,   4.,   3.,   6.,   8.,   9.,   5.,   4.,   3.,   1.,   1.,\n",
       "         6.,   6.,   3.,   1.,   0.,   6.,   6.,   1.,   3.,   2.,   6.,\n",
       "        10.])], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([ 3.,  6.,  6.,  6.,  3.,  8.,  6.,  6.,  8.,  3.,  6.,  6.,  6.,\n",
       "        3.,  8.,  6.,  6.,  3.,  3.,  6.,  3.,  6.,  6.,  6.,  3.,  3.,\n",
       "        6.,  6.,  8.,  3.,  6.,  6.,  6.,  3.]),\n",
       "       array([ 6.,  6.,  6.,  3.,  8.,  6.,  6.,  8.,  3.,  6.,  6.,  6.,  3.,\n",
       "        3.,  6.,  6.,  8.,  3.,  6.,  6.,  6.,  6.,  6.,  3.,  3.,  6.,\n",
       "        6.,  8.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  3.,  3.,\n",
       "        6.,  6.,  6.,  6.,  3.,  3.,  6.,  6.,  8.,  3.,  8.,  6.,  6.,\n",
       "        3.,  3.,  6.,  6.,  6.]),\n",
       "       array([ 8.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  8.,  3.,  6.,  6.,\n",
       "        6.,  3.,  3.,  6.,  6.,  8.,  3.,  6.,  3.,  8.,  6.,  6.,  8.,\n",
       "        3.,  8.,  6.,  6.,  3.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,\n",
       "        6.,  6.,  3.,  8.,  6.,  6.]),\n",
       "       array([ 3.,  6.,  6.,  6.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,\n",
       "        3.,  3.,  6.,  6.,  6.,  3.,  3.,  3.,  6.,  6.,  8.,  3.,  8.,\n",
       "        6.,  6.,  3.,  3.,  6.]),\n",
       "       array([ 6.,  8.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  3.,  3.,\n",
       "        6.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  8.,  3.,  6.]),\n",
       "       array([ 3.,  3.,  6.,  6.,  8.,  3.,  6.,  6.,  6.,  3.,  8.,  6.,  6.]),\n",
       "       array([ 8.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  3.,  8.,  6.,\n",
       "        6.,  3.,  3.,  6.,  6.,  6.,  3.,  8.,  3.,  6.,  6.,  6.,  3.,\n",
       "        3.,  6.,  6.,  6.,  8.,  8.,  6.,  6.,  8.,  3.,  6.,  6.,  6.,\n",
       "        3.,  8.,  3.,  8.,  6.,  6.,  8.,  3.,  8.,  6.,  6.,  3.,  3.,\n",
       "        6.,  6.]),\n",
       "       array([ 6.,  6.,  6.,  3.,  8.,  6.,  6.,  8.,  3.,  6.,  6.,  6.,  3.]),\n",
       "       array([ 6.,  6.,  3.,  3.,  6.,  6.,  8.,  3.,  8.,  6.,  6.,  3.,  3.,\n",
       "        6.,  6.,  6.,  3.,  8.]),\n",
       "       array([ 6.,  6.,  3.,  3.,  6.,  6.,  8.,  3.,  6.,  6.,  6.,  3.,  3.,\n",
       "        6.,  6.,  8.,  3.,  6.,  6.,  6.,  6.,  6.,  3.,  3.,  6.,  6.,\n",
       "        6.,  3.,  3.,  6.,  6.,  6.,  3.,  8.,  6.,  6.,  8.,  3.,  6.,\n",
       "        6.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  3.,  8.,  6.,  6.,  8.,\n",
       "        3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  6.,  3.,  3.,  6.,\n",
       "        6.,  6.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  3.,  8.,\n",
       "        6.,  6.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  3.,  3.,  6.,  6.,\n",
       "        6.,  3.,  8.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  6.,  3.,  3.,\n",
       "        6.,  6.,  6.,  3.,  3.,  6.,  6.,  6.,  3.,  3.,  6.,  6.,  8.,\n",
       "        3.,  8.,  6.,  6.,  6.])], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_true = numpy.concatenate(true)\n",
    "all_predicted = numpy.concatenate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
