{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris Simple Example\n",
    "=====\n",
    "\n",
    "This example shows how to use QuickExperiment to define an experiment suite for quick iterations and high result reproducibility. It uses the sklearn Iris dataset and a simple Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the dataset, which is already preprocess into a numeric matrix and an array of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first example, we are only going to train a classifier, evaluate it over a test portion and save the results. For this, we will need to use an instance of BaseDataset and define the Experiment configuration.\n",
    "\n",
    "Our dataset consitst in a 2-D numpy array representing the instances, and a vector representing the labels. We can use the class SimpleDataset to model our data.\n",
    "\n",
    "BaseDatasets are created to optimize the stored information for a dataset that will be used many times, and likely partitioned in many ways. Over the course of an investigation, numerous experiments will be run and re-runned on a dataset, each time creating training and evaluation partitions. Instead of saving an entire copy of the matrixes for every partition, BaseDatasets stores the matrix only once and keeps the indices of the instances assigned to each partition. This also allows to compare results between experiments better and keep track of where the instances of the original dataset are being used.\n",
    "\n",
    "Let's create our Dataset instance: first, we need to create the train/test split of the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "train_index, test_index = next(splitter.split(iris.data, iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this indices to create an instance of BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add parent directory to python path\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset import SimpleDataset\n",
    "\n",
    "iris_dataset = SimpleDataset()\n",
    "indices = {'train': train_index, 'test': test_index}\n",
    "iris_dataset.create_from_matrixes(iris.data, indices, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now the experiment we want to run using a configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "config = {\n",
    "    'model': LogisticRegression,\n",
    "    'model_params': {'C': 0.5, 'n_jobs': 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import experiment\n",
    "experiment = reload(experiment)\n",
    "lr_experiment = experiment.Experiment(iris_dataset, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partition_sizes = {'train': 0.8, 'test': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
